{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenetv2_1.00_224 (Func  (None, 8, 8, 1280)        2257984   \n",
      " tional)                                                         \n",
      "                                                                 \n",
      " global_average_pooling2d_2  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 12)                1548      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2423500 (9.24 MB)\n",
      "Trainable params: 165516 (646.55 KB)\n",
      "Non-trainable params: 2257984 (8.61 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa  # Import the tensorflow_addons module\n",
    "\n",
    "# Set image size and number of classes\n",
    "img_size = (244, 244)\n",
    "num_classes = 12  # Replace with the actual number of classes in your dataset\n",
    "\n",
    "# Load MobileNetV2 pre-trained on ImageNet data\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(img_size[0], img_size[1], 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Freeze the convolutional base\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create your own model on top of MobileNetV2\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model using Rectified Adam (RAdam) optimizer from tensorflow_addons\n",
    "radam_optimizer = tfa.optimizers.RectifiedAdam(learning_rate=1e-4)\n",
    "model.compile(optimizer=radam_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15516 images belonging to 12 classes.\n",
      "Found 4944 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation and Preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Assuming you have a directory structure with train and validation sets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/Users/kevinsam/Desktop/Unif/Master/ThesisWheelchair/DATA/RoadSaW/RoadSaW-075_s/train',\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    '/Users/kevinsam/Desktop/Unif/Master/ThesisWheelchair/DATA/RoadSaW/RoadSaW-075_s/validation',\n",
    "    target_size=img_size,\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model in two steps as described\n",
    "#### First step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "485/485 [==============================] - 221s 451ms/step - loss: 2.2592 - accuracy: 0.2365 - val_loss: 1.7777 - val_accuracy: 0.4780\n",
      "Epoch 2/10\n",
      "485/485 [==============================] - 219s 452ms/step - loss: 1.5465 - accuracy: 0.4541 - val_loss: 1.5334 - val_accuracy: 0.5336\n",
      "Epoch 3/10\n",
      "485/485 [==============================] - 220s 453ms/step - loss: 1.3108 - accuracy: 0.5242 - val_loss: 1.4174 - val_accuracy: 0.5415\n",
      "Epoch 4/10\n",
      "485/485 [==============================] - 222s 458ms/step - loss: 1.1788 - accuracy: 0.5666 - val_loss: 1.3324 - val_accuracy: 0.5629\n",
      "Epoch 5/10\n",
      "485/485 [==============================] - 222s 457ms/step - loss: 1.0889 - accuracy: 0.5951 - val_loss: 1.2806 - val_accuracy: 0.5690\n",
      "Epoch 6/10\n",
      "485/485 [==============================] - 221s 455ms/step - loss: 1.0319 - accuracy: 0.6088 - val_loss: 1.2348 - val_accuracy: 0.5702\n",
      "Epoch 7/10\n",
      "485/485 [==============================] - 220s 454ms/step - loss: 0.9835 - accuracy: 0.6264 - val_loss: 1.2055 - val_accuracy: 0.5858\n",
      "Epoch 8/10\n",
      "485/485 [==============================] - 221s 455ms/step - loss: 0.9462 - accuracy: 0.6342 - val_loss: 1.1900 - val_accuracy: 0.5793\n",
      "Epoch 9/10\n",
      "485/485 [==============================] - 221s 456ms/step - loss: 0.9064 - accuracy: 0.6485 - val_loss: 1.1474 - val_accuracy: 0.5817\n",
      "Epoch 10/10\n",
      "485/485 [==============================] - 224s 462ms/step - loss: 0.8819 - accuracy: 0.6560 - val_loss: 1.1207 - val_accuracy: 0.5949\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.optimizers' has no attribute 'RAdam'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m radam_optimizer2 \u001b[38;5;241m=\u001b[39m tfa\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mRectifiedAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Lower the learning rate for fine-tuning\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRAdam\u001b[49m(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.optimizers' has no attribute 'RAdam'"
     ]
    }
   ],
   "source": [
    "\n",
    "hist1 = model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the convolutional base for fine-tuning\n",
    "base_model.trainable = True\n",
    "radam_optimizer2 = tfa.optimizers.RectifiedAdam(learning_rate=1e-5)\n",
    "# Lower the learning rate for fine-tuning\n",
    "model.compile(optimizer=radam_optimizer2, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "460/485 [===========================>..] - ETA: 24s - loss: 2.3134 - accuracy: 0.2896"
     ]
    }
   ],
   "source": [
    "hist2 = model.fit(train_generator, epochs=10, validation_data=validation_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
